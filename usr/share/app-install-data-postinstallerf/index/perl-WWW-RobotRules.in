#!/bin/sh
Name='<b>perl-WWW-RobotRules</b>'
Comment='<span size="xx-large">Database of robots.txt-derived permissions</span>'
Comment3='
This module parses /robots.txt files as specified in "A Standard for Robot
Exclusion", at <http//www.robotstxt.org/wc/norobots.html>. Webmasters can
use the /robots.txt file to forbid conforming robots from accessing parts
of their web site.
'
License='GPL+ or Artistic'
Screenshot=''
Url='http://search.cpan.org/dist/WWW-RobotRules/'
export Comment
export Name
export Comment3
export License
export Screenshot
export Url
